There main program of this 2distribution" is bn_contd_learner.
It takes 8 (9th is optional) arguments:

1) vdfile       -- description of the values of the data
2) datafile     -- actual data file
3) datacount    -- number of rows in the actual datafile
4) ess          -- Equivalent Sample Size
5) reportfile   -- Statistics about search
6) structfile   -- Structure of the Bayesian network
7) searchtime   -- Searchtime in seconds
8) maxtblsize   -- Maximum size of probability tables
9) pidfile      -- File containing the PID of the search process 

Here are the more detailed descriptions of the parameters:

2) data file:
-------------
- One data vector per row. 
- The variables of the vector separated by whitespace. 
- The values of the i:th variable can be integers in
  [0, <number of tabulators on i:th row of vdfile>], 
  -1 marking the missing value.

1) vd file:
-----------
- i:th row of the file describes i:th variable of the data.
- Format:<name><tab><value_1><tab><value_2><tab>....<tab><value_n>
- See example files for iris

3) datacount:
-------------
- Number of rows in the actual datafile i.e number of 
  data vectors

4) ess:
-------
- Technical parameter describing the parameter priors for the Bayesian
  Network.
- Popular choices are 1.0 and 
  0.5*(number of tabulators in vdfile) / (number of rows in vdfile)

5) reportfile:
--------------
- Name of the output file containing statistics about search
- This file is written when the program ends and also when the program
  receives USR1 signal.
- The file contains 5 numbers:
  1: number of models searched (estimate)
  2: number of models searched since last report (estimate)
  3: number of models searched after current best model (estimate)
  4: prob ratio of current best model and last report's best model
  5: log probability of the current best model

6) structfile:
--------------
- Initial structure of the network where the search starts.
- The actual result of the search when the search ends
  or when the search process receives USR1 signal.
- The first line of the structfile contains the number of 
  variables i.e the number of nodes in the network.
- Then there is one line per variable so that in structfile
  (i+1)th line contains information about i:th node (i:th variable)
  of the network.
- The line describing the variable V_i has the following information: 
  <Number of Children of V_i> 
  <Number of parents of V_i> 
  <Indices of parents of V_i> indexed from zero on

  i.e if the 7th line of the structfile looks like
      2 3 0 4 5
  it means that 6th variable (the one described on the sixth row of 
  vdfile) has two children (we do not tell which) and 3 parents
  namely 1st, 5th and 6th variable (described on the 1st, 5th and 6th rows of 
  vdfile respectively and having indices 0, 4 and 5 when indexed from zero)

- Parents of the variable X (node) are those nodes from which the is an arrow
  to X and children of X are those variable to which there are arcs from X.

7) searchtime:
--------------
- The duration of the search program in seconds. If <0 then the search goes on
  forever unless it receives USR2 signal.

8) maxtblsize:
--------------
- maximum size of any single probability table in the network.
  In Bayesian network each node X has a probability table that has 
  as many entries that there are possible value combinations of the
  parent variables of the node (times number of values of X). 
  So if X has many parents with many values these tables can be 
  huge. Big tables also make learning slow. 10000 is a good value ;)

9) pidfile:      
----------
 - File containing the process id of the search process. Useful
   to find out the process to send signals to. If this parameter
   is not given, the PID is printed to standard output. 


To generate an initial structure for the search there is a program
bflearner. It learns an optimal forest structured Bayesian network
(NB. all the orderings of this structure that form a forest are equally 
probable). The algorithm is quadratic as a function of number of variables so
for very many variables (say hundreds) it may be too slow.

In data directory there is a small example data set, so after 
./configure && make you may try to say:

 src/bflearner data/iris.vd data/iris.idt 150 1 data/iris.str

This actually should build a Bayesian tree to the file data/iris.str and 
print out non-normalized log-probability of the structure (=-453.047383).

cat data/iris.str should give

5
1 0
0 1 3
1 1 0
1 1 4
1 1 2

You may now use this structure as an initial structure for network learner

src/bn_contd_learner data/iris.vd data/iris.idt 150 1 rep data/iris.str 5 1000

After about 5 seconds the program should exit and the result is again in 
data/iris.st (NB. the initial structure was destroyed, so you better save it
if you need it later) The last column of rep (=-452.214297) tells you that
the new model is more probable than the forest-model
actually exp(-452.214297 - -453.047383) = 2.3 times as probable.
